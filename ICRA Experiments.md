
除了案例研究之外，还进行了额外的实验，以评估该框架的特定属性。所有运行均在 Ignition 仿真中执行，迭代预算为 25,000 次 rollout，并使用与第 \ref{sec:case_study} 节中定义的相同奖励函数。性能通过生成可执行轨迹的能力以及奖励在迭代过程中的收敛性来进行评估。

**双图校验与 RAG 的稳健性**  
为验证校验与修复机制的稳健性，我们设计了两种对比方案：（1）由 LLM 拆解任务，并结合双图校验与 RAG 修复生成行为树骨架；（2）在相同任务描述下，人为删除 LLM 拆解过程中的部分 prompt 信息，仅进行双图校验而不启用修复机制。两种方案均使用相同的任务描述、相同的 LLM 基座模型以及一致的校验系统。

结果显示，在未修改的 prompt 条件下，双图校验与 RAG 修复能够生成可在仿真中顺利执行的行为树骨架（随机填充参数）。而在 prompt 被削弱的条件下，双图校验能够准确识别逻辑错误和数据流断裂，但若不经修复，则无法得到可运行的行为树骨架。该实验表明，骨架生成系统在保持鲁棒性的同时，prompt、双图校验和 RAG 修复模块各自发挥了不可或缺的作用。

**仅使用 LLM 参数组合 vs. MCTS 优化参数组合**  
为验证参数调优的必要性，我们比较了两种策略：（1）直接使用 LLM 生成的参数先验表，并选取其中概率最高的组合；（2）通过 MCTS 搜索得到的优化组合。在实验中，前者将 LLM 提出的参数直接实例化到行为树骨架中，不再进行进一步搜索，并在 Ignition 仿真中执行。对于 MCTS 基线，相同骨架在 25,000 次 rollout 中结合仿真反馈进行优化。

结果： LLM-only 生成的参数组合常出现轨迹不可行的情况，例如与目标物体发生碰撞、无法正确接触物体，或出现冗余旋转导致严重超时，整体得分集中在40-60分。这表明仅依赖 LLM 的语义推理，难以捕捉参数之间的耦合关系。相比之下，MCTS 优化后的参数组合能够稳定生成无碰撞、按时完成的运动轨迹，且动作更加简洁，得分普遍在90分以上。这说明搜索过程在弥合语言生成与可执行性之间的差距中至关重要。

**LLM 先验的作用**  
为了评估参数先验的价值，我们比较了两种 MCTS 初始化策略：（1）使用 LLM 根据任务语境生成的先验分布；（2）对所有候选参数采用均匀分布。在其他条件一致的情况下，两者均运行 25,000 次 rollout。

结果：两种方案最终均能收敛，但使用 LLM 先验时，达到最佳组合所需的收敛速度比均匀分布的参数方案平均快约 40%。在均匀初始化下，大量探索和 rollout 被浪费在不可行的规划器上；而引入 LLM 先验后，搜索能够更快聚焦于语义合理的参数区域，从而有效缩小搜索空间，减少无效探索。

**EMA 与 BS 更新的比较**  
我们比较了在回传阶段用于细化先验的两种更新策略。在两种情况下，均采用相同的行为树骨架和奖励函数，并各自运行 25,000 次 rollout。指数移动平均（EMA）根据近期结果对概率进行平滑更新，而贝叶斯采样（BS）则基于成功与失败构建 Beta 分布以更新概率。

结果：EMA 能更快达到奖励阈值，体现了其对快速收敛的偏好。然而，EMA 有时会过早收敛，导致探索不足；相较之下，BS 在保持高频成功参数逐步稳定收敛的同时，仍为低频参数保留一定探索空间。值得注意的是，BS 的结果还可以用来检验 EMA 所选参数的稳健性。总体而言，EMA 与 BS 形成了一种互补关系：前者强调收敛速度，后者增强了避免陷入局部最优的鲁棒性。

**不同 LLM 的比较**  
为评估框架对语言模型选择的敏感性，我们将 GPT-5 替换为 GPT-4o-mini 来生成参数先验，并在相同的行为树骨架和奖励函数下运行 MCTS。

结果： 得益于更强的语义理解与推理能力，GPT-5 提供的先验分布更准确，使 MCTS 的收敛速度提升约 5%–8%。然而，由于最终性能主要取决于搜索与仿真反馈，两种模型在优化收敛后的结果上差异不大。这表明更强的语言模型能够减少探索开销，但并非最终性能的决定性因素；在资源受限的场景下，小模型同样可以满足需求。

---